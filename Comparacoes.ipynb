{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "import torch.optim as optim\n",
    "#from matplotlib import pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import torch.utils.data as data\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.utils import save_image\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import albumentations as A\n",
    "from Diffusion import GaussianDiffusionSampler, GaussianDiffusionTrainer\n",
    "from Diffusion.Model import UNet\n",
    "from src.Scheduler import GradualWarmupScheduler\n",
    "from src.tool_func import *\n",
    "from tensorboardX import SummaryWriter #provavelmente irei retirar o suporte a tensorboard\n",
    "from skimage.metrics import peak_signal_noise_ratio as PSNR\n",
    "from skimage.metrics import structural_similarity as SSIM \n",
    "from Metrics.metrics import nmetrics\n",
    "import numpy as np\n",
    "import glob\n",
    "import random\n",
    "import cv2\n",
    "import colorsys\n",
    "import os\n",
    "from typing import Dict, List\n",
    "import PIL\n",
    "import lpips as lpips\n",
    "from PIL import Image\n",
    "import lpips\n",
    "import time\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "import random\n",
    "from src.split_data import check_alpha_channel, load_image_paths\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparacoes usando os dados e a inferencia dos datatasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class load_data(data.Dataset):\n",
    "    def __init__(self, input_data_low, input_data_high):\n",
    "        self.input_data_low = input_data_low\n",
    "        self.input_data_high = input_data_high\n",
    "        print(\"Total training examples:\", len(self.input_data_high))\n",
    "        self.transform=A.Compose(\n",
    "            [\n",
    "                A.Resize (height=256, width=256),\n",
    "                #A.RandomCrop(height=128, width=128),\n",
    "                A.HorizontalFlip(p=0.5),\n",
    "                A.VerticalFlip(p=0.5),\n",
    "                ToTensorV2(),\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "\n",
    "\n",
    "    def __len__(self):  \n",
    "        return len(self.input_data_low)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seed = torch.random.seed()\n",
    "        data_low = cv2.imread(self.input_data_low[idx])\n",
    "\n",
    "        data_low = cv2.convertScaleAbs(data_low, alpha=1.0, beta=-random.randint(50, 100)) #modificação para ajuste automatico de brilho para datalow\n",
    "\n",
    "        data_low=data_low[:,:,::-1].copy()\n",
    "        random.seed(1)\n",
    "        data_low=data_low/255.0\n",
    "\n",
    "        data_low=np.power(data_low,0.5)#0.25 # Aplicação da correção gamma ajustada para imagens subaquáticas\n",
    "        data_low = self.transform(image=data_low)[\"image\"]\n",
    "        #mean and var of lol training dataset. If you change dataset, please change mean and var.\n",
    "        ##RGB normalization\n",
    "        #mean=torch.tensor([0.2255, 0.4897, 0.4174])\n",
    "        #var=torch.tensor([0.0259, 0.0338, 0.0383])\n",
    "        mean=torch.tensor([0.4350, 0.4445, 0.4086])\n",
    "        var=torch.tensor([0.0193, 0.0134, 0.0199])\n",
    "        ##BGR normalization\n",
    "        #mean=torch.tensor([0.4174, 0.4897, 0.2255])\n",
    "        #var=torch.tensor([0.0383, 0.0338, 0.0259])\n",
    "        data_low=(data_low-mean.view(3,1,1))/var.view(3,1,1)\n",
    "        data_low=data_low/30#20\n",
    "\n",
    "        data_max_r=data_low[0].max()\n",
    "        data_max_g = data_low[1].max()\n",
    "        data_max_b = data_low[2].max()\n",
    "        color_max=torch.zeros((data_low.shape[0],data_low.shape[1],data_low.shape[2]))\n",
    "        color_max[0,:,:]=data_max_r*torch.ones((data_low.shape[1],data_low.shape[2]))    \n",
    "        color_max[1,:, :] = data_max_g * torch.ones((data_low.shape[1], data_low.shape[2]))\n",
    "        color_max[2,:, :] = data_max_b * torch.ones((data_low.shape[1], data_low.shape[2]))\n",
    "        data_color=data_low/(color_max + 1e-6)\n",
    "\n",
    "        data_high = cv2.imread(self.input_data_high[idx])\n",
    "\n",
    "        data_high = cv2.convertScaleAbs(data_high, alpha=1.0, beta=random.randint(50, 100)) #modificação para ajuste automatico de brilho para datalow\n",
    "\n",
    "        data_high=data_high[:,:,::-1].copy()\n",
    "        #data_high = Image.fromarray(data_high)\n",
    "        random.seed(1)\n",
    "        data_high = self.transform(image=data_high)[\"image\"]/255.0\n",
    "        data_high=data_high*2-1\n",
    "\n",
    "        data_blur = data_low.permute(1, 2, 0).numpy() * 255.0\n",
    "        data_blur = cv2.blur(data_blur, (5, 5))\n",
    "        data_blur = data_blur * 1.0 / 255.0\n",
    "        data_blur = torch.Tensor(data_blur).float().permute(2, 0, 1)\n",
    "\n",
    "        return [data_low, data_high,data_color,data_blur]\n",
    "\n",
    "\n",
    "\n",
    "class load_data_test(data.Dataset):\n",
    "    def __init__(self, input_data_low, input_data_high):\n",
    "        self.input_data_low = input_data_low\n",
    "        self.input_data_high = input_data_high\n",
    "        print(\"Total test-training examples:\", len(self.input_data_high))\n",
    "        self.transform=A.Compose(\n",
    "            [\n",
    "                A.Resize (height=256, width=256),\n",
    "                ToTensorV2(),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_data_low)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seed = torch.random.seed()\n",
    "\n",
    "        data_low = cv2.imread(self.input_data_low[idx])\n",
    "\n",
    "        #data_low = cv2.convertScaleAbs(data_low, alpha=1.0, beta=-75) #modificação para ajuste automatico de brilho para datalow\n",
    "\n",
    "        ### Processamento das imagens // Avaliar aplicação // funcionalizar\n",
    "        # Conversão de canais de cor e normalização\n",
    "        data_low=data_low[:,:,::-1].copy()\n",
    "        random.seed(1)\n",
    "        data_low=data_low/255.0\n",
    "        # Aplicação de correção gamma\n",
    "        data_low=np.power(data_low,0.5)\n",
    "\n",
    "        # Transformação e normalização\n",
    "        data_low = self.transform(image=data_low)[\"image\"]\n",
    "        mean=torch.tensor([0.4350, 0.4445, 0.4086])\n",
    "        var=torch.tensor([0.0193, 0.0134, 0.0199])\n",
    "        #mean = torch.tensor([0.4174, 0.4897, 0.2255])\n",
    "        #var = torch.tensor([0.0383, 0.0338, 0.0259])\n",
    "        #mean=torch.tensor([0.2255, 0.4897, 0.4174])\n",
    "        #var=torch.tensor([0.0259, 0.0338, 0.0383])\n",
    "        data_low=(data_low-mean.view(3,1,1))/var.view(3,1,1)\n",
    "        data_low=data_low/20\n",
    "\n",
    "        # Calcular máximos dos canais de cor e normalização de cor\n",
    "        data_max_r=data_low[0].max()\n",
    "        data_max_g = data_low[1].max()\n",
    "        data_max_b = data_low[2].max()\n",
    "        color_max=torch.zeros((data_low.shape[0],data_low.shape[1],data_low.shape[2]))\n",
    "        color_max[0,:,:]=data_max_r*torch.ones((data_low.shape[1],data_low.shape[2]))    \n",
    "        color_max[1,:, :] = data_max_g * torch.ones((data_low.shape[1], data_low.shape[2]))\n",
    "        color_max[2,:, :] = data_max_b * torch.ones((data_low.shape[1], data_low.shape[2]))\n",
    "        data_color=data_low/(color_max+ 1e-6)\n",
    "        #data_color = self.transform(data_color)\n",
    "        #data_color=torch.from_numpy(data_color).float()\n",
    "        #data_color=data_color.permute(2,0,1)\n",
    "\n",
    "        # Processamento da imagem de alta luminosidade\n",
    "        data_high = cv2.imread(self.input_data_high[idx])\n",
    "\n",
    "        #data_high= cv2.convertScaleAbs(data_high, alpha=1.0, beta=50)\n",
    "\n",
    "        data_high=data_high[:,:,::-1].copy()\n",
    "        #data_high = Image.fromarray(data_high)\n",
    "        random.seed(1)\n",
    "        data_high = self.transform(image=data_high)[\"image\"]/255.0\n",
    "        data_high=data_high*2-1\n",
    "\n",
    "        #normalization\n",
    "        #data_high=data_high**0.25\n",
    "\n",
    "        # Desfocagem e preparação do retorno\n",
    "        data_blur = data_low.permute(1, 2, 0).numpy() * 255.0\n",
    "        data_blur = cv2.blur(data_blur, (5, 5))\n",
    "        data_blur = data_blur * 1.0 / 255.0\n",
    "        data_blur = torch.Tensor(data_blur).float().permute(2, 0, 1)\n",
    "\n",
    "\n",
    "        return [data_low, data_high,data_color,data_blur,self.input_data_low[idx]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Test(config: Dict,epoch):\n",
    "\n",
    "    ###load the data\n",
    "    datapath_test = load_image_paths(config.dataset_path,config.dataset,split=False)\n",
    "\n",
    "    # load model and evaluate\n",
    "    device = config.device_list[0]\n",
    "    # test_low_path=config.dataset_path+r'*.png'    \n",
    "    # test_high_path=config.dataset_path+r'*.png' \n",
    "\n",
    "    # datapath_test_low = glob.glob( test_low_path)\n",
    "    # datapath_test_high = glob.glob(test_high_path)\n",
    "\n",
    "    dataload_test = load_data_test(datapath_test,datapath_test)\n",
    "    dataloader = DataLoader(dataload_test, batch_size=1, num_workers=4,\n",
    "                            drop_last=True, pin_memory=True)\n",
    "\n",
    "\n",
    "    model = UNet(T=config.T, ch=config.channel, ch_mult=config.channel_mult,\n",
    "                 attn=config.attn,\n",
    "                 num_res_blocks=config.num_res_blocks, dropout=0.)\n",
    "    #Mudar um pouco aqui para carregar o checkpoint do dataset escolhido\n",
    "    ckpt_path=config.output_path+'ckpt/'+ config.dataset +'/ckpt_'+str(epoch)+'_.pt'\n",
    "    ckpt = torch.load(ckpt_path,map_location='cpu')\n",
    "    model.load_state_dict({k.replace('module.', ''): v for k, v in ckpt.items()})\n",
    "    print(\"model load weight done.\")\n",
    "    save_dir=config.output_path+'/result/'+ config.dataset +'/epoch/'+str(epoch)+'/'\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    print(f\"savedir: {save_dir}, ckpt_path: {ckpt_path}\")\n",
    "    # save_txt_name =save_dir + 'res.txt'\n",
    "    # f = open(save_txt_name, 'w+')\n",
    "    # f.close()\n",
    "        \n",
    "    image_num = 0\n",
    "    psnr_list = []\n",
    "    ssim_list = []\n",
    "    #lpips_list=[]\n",
    "    uciqe_list = []\n",
    "    uiqm_list =[]\n",
    "    wout = []\n",
    "\n",
    "\"\"\" \n",
    "    model.eval()\n",
    "    sampler = GaussianDiffusionSampler(\n",
    "        model, config.beta_1, config.beta_T, config.T).to(device)\n",
    "    #loss_fn_vgg=lpips.LPIPS(net='vgg')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        with tqdm( dataloader, dynamic_ncols=True) as tqdmDataLoader:\n",
    "                image_num = 0\n",
    "                for data_low, data_high, data_color,data_blur,filename in tqdmDataLoader:\n",
    "                    name=filename[0].split('/')[-1]\n",
    "                    print('Image:',name)\n",
    "                    gt_image = data_high.to(device)\n",
    "                    lowlight_image = data_low.to(device)\n",
    "                    data_color = data_color.to(device)\n",
    "                    data_blur=data_blur.to(device)\n",
    "                    snr_map = getSnrMap(lowlight_image, data_blur)\n",
    "                    data_concate=torch.cat([data_color, snr_map], dim=1)\n",
    "\n",
    "                    #for i in range(-10, 10,1): \n",
    "                        # light_high = torch.ones([1]) * i*0.1\n",
    "                        # light_high = light_high.to(device)\n",
    "                        \n",
    "                    brightness_level=gt_image.mean([1, 2, 3]) # b*1\n",
    "                    time_start = time.time()\n",
    "                    sampledImgs = sampler(lowlight_image, data_concate,brightness_level,ddim=True,\n",
    "                                          unconditional_guidance_scale=1,ddim_step=config.ddim_step)\n",
    "                    time_end=time.time()\n",
    "                    print('time cost:', time_end - time_start)\n",
    "\n",
    "                    sampledImgs=(sampledImgs+1)/2\n",
    "                    gt_image=(gt_image+1)/2\n",
    "                    lowlight_image=(lowlight_image+1)/2\n",
    "                    res_Imgs=np.clip(sampledImgs.detach().cpu().numpy()[0].transpose(1, 2, 0),0,1)[:,:,::-1] \n",
    "                    gt_img=np.clip(gt_image.detach().cpu().numpy()[0].transpose(1, 2, 0),0,1)[:,:,::-1]\n",
    "                    low_img=np.clip(lowlight_image.detach().cpu().numpy()[0].transpose(1, 2, 0),0,1)[:,:,::-1]\n",
    "                    \n",
    "                    \n",
    "                    # Compute METRICS\n",
    "                    ## compute psnr\n",
    "                    psnr = PSNR(res_Imgs, gt_img)\n",
    "                    #ssim = SSIM(res_Imgs, gt_img, channel_axis=2,data_range=255)\n",
    "                    res_gray = rgb2gray(res_Imgs)\n",
    "                    gt_gray = rgb2gray(gt_img)\n",
    "\n",
    "                    ssim_score = SSIM(res_gray, gt_gray, multichannel=True,data_range=1)\\\n",
    "                    \n",
    "                    #UIQM e UCIQE\n",
    "                    uiqm,uciqe = nmetrics(res_Imgs)\n",
    "                   \n",
    "                    res_Imgs = (res_Imgs * 255)\n",
    "                    gt_img = (gt_img * 255)\n",
    "                    low_img = (low_img * 255)\n",
    "                    \n",
    "                    psnr_list.append(psnr)\n",
    "                    ssim_list.append(ssim_score)\n",
    "                    uiqm_list.append(uiqm)\n",
    "                    uciqe_list.append(uciqe)\n",
    "                    \n",
    "\n",
    "                    #send wandb\n",
    "                    output = np.concatenate([low_img, gt_img, res_Imgs], axis=1) / 255\n",
    "                    #image = wandb.Image(output, caption=\"Low image, High Image, Enhanced Image\")\n",
    "                    #wout.append(image)\n",
    "\n",
    "                    # show result\n",
    "                    # output = np.concatenate([low_img, gt_img, res_Imgs, res_trick], axis=1) / 255\n",
    "                    # plt.axis('off')\n",
    "                    # plt.imshow(output)\n",
    "                    # plt.show()\n",
    "                    #save_path = save_dir + name\n",
    "                    #cv2.imwrite(save_path, output * 255)\n",
    "\n",
    "                    #save_path =save_dir+ name+'.png'\n",
    "                    #cv2.imwrite(save_path, res_Imgs)\n",
    "                \n",
    "                #Metrics\n",
    "  \n",
    "                avg_psnr = sum(psnr_list) / len(psnr_list)\n",
    "                avg_ssim = sum(ssim_list) / len(ssim_list)\n",
    "                avg_uiqm = sum(uiqm_list) / len(uiqm_list)\n",
    "                avg_uciqe = sum(uciqe_list) / len(uciqe_list)\n",
    "\n",
    "                # Wandb logs \n",
    "                wandb.log({\"Inferecia \"+config.dataset:{\n",
    "                    \"Average PSNR\": avg_psnr,\n",
    "                    \"Average SSIM\": avg_ssim,\n",
    "                    \"Average UIQM\": avg_uiqm,\n",
    "                    \"Average UCIQE\": avg_uciqe,\n",
    "                    \"PSNR\": psnr,\n",
    "                    \"SSIM\": ssim_score,\n",
    "                    \"Test from epoch\": epoch,\n",
    "                    \"Image \":wout\n",
    "                    }})\n",
    "\n",
    "                #print('psnr_orgin_avg:', avg_psnr)\n",
    "                #print('ssim_orgin_avg:', avg_ssim)\n",
    "                print(f\"Test From epoch {epoch} DONE\")\n",
    "\n",
    "                # f = open(save_txt_name, 'w+')\n",
    "                # f.write('\\npsnr_orgin :')\n",
    "                # f.write(str(psnr_list))\n",
    "                # f.write('\\nssim_orgin :')\n",
    "                # f.write(str(ssim_list))\n",
    "\n",
    "                # f.write('\\npsnr_orgin_avg:')\n",
    "                # f.write(str(avg_psnr))\n",
    "                # f.write('\\nssim_orgin_avg:')\n",
    "                # f.write(str(avg_ssim))\n",
    "                # f.close()\n",
    "\n",
    "                #return avg_psnr,avg_ssim\n",
    " \"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Testi(config: Dict,epoch):\n",
    "\n",
    "    ###load the data\n",
    "    datapath_test = load_image_paths(config.dataset_path,config.dataset,split=False)[:5]\n",
    "\n",
    "    # load model and evaluate\n",
    "    device = config.device_list[0]\n",
    "    # test_low_path=config.dataset_path+r'*.png'    \n",
    "    # test_high_path=config.dataset_path+r'*.png' \n",
    "\n",
    "    # datapath_test_low = glob.glob( test_low_path)\n",
    "    # datapath_test_high = glob.glob(test_high_path)\n",
    "\n",
    "    dataload_test = load_data_test(datapath_test,datapath_test)\n",
    "    dataloader = DataLoader(dataload_test, batch_size=1, num_workers=4,\n",
    "                            drop_last=True, pin_memory=True)\n",
    "\n",
    "\n",
    "    model = UNet(T=config.T, ch=config.channel, ch_mult=config.channel_mult,\n",
    "                 attn=config.attn,\n",
    "                 num_res_blocks=config.num_res_blocks, dropout=0.)\n",
    "    #Mudar um pouco aqui para carregar o checkpoint do dataset escolhido\n",
    "    ckpt_path=config.output_path+'ckpt/'+ config.dataset +'/ckpt_'+str(epoch)+'_.pt'\n",
    "    ckpt = torch.load(ckpt_path,map_location='cpu')\n",
    "    model.load_state_dict({k.replace('module.', ''): v for k, v in ckpt.items()})\n",
    "    print(\"model load weight done.\")\n",
    "    save_dir=config.output_path+'result/'+ config.dataset+'/ctrl' +'/epoch/'+str(epoch)+'/'\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    # save_txt_name =save_dir + 'res.txt'\n",
    "    # f = open(save_txt_name, 'w+')\n",
    "    # f.close()\n",
    "\n",
    "    image_num = 0\n",
    "    psnr_list = []\n",
    "    ssim_list = []\n",
    "    #lpips_list=[]\n",
    "    uciqe_list = []\n",
    "    uiqm_list =[]\n",
    "    wout = []\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    sampler = GaussianDiffusionSampler(\n",
    "        model, config.beta_1, config.beta_T, config.T).to(device)\n",
    "    #loss_fn_vgg=lpips.LPIPS(net='vgg')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        with tqdm( dataloader, dynamic_ncols=True) as tqdmDataLoader:\n",
    "                image_num = 0\n",
    "                for data_low, data_high, data_color,data_blur,filename in tqdmDataLoader:\n",
    "                    name=filename[0].split('/')[-1]\n",
    "                    print('Image:',name)\n",
    "                    gt_image = data_high.to(device)\n",
    "                    lowlight_image = data_low.to(device)\n",
    "                    data_color = data_color.to(device)\n",
    "                    data_blur=data_blur.to(device)\n",
    "                    snr_map = getSnrMap(lowlight_image, data_blur)\n",
    "                    data_concate=torch.cat([data_color, snr_map], dim=1)\n",
    "\n",
    "                    for i in range(-8, 8): \n",
    "                        light_high = torch.ones([1]) * i*0.1\n",
    "                        light_high = light_high.to(device)\n",
    "                        \n",
    "                        brightness_level=gt_image.mean([1, 2, 3]) # b*1\n",
    "                        time_start = time.time()\n",
    "                        sampledImgs = sampler(lowlight_image, data_concate,brightness_level,ddim=True,\n",
    "                                            unconditional_guidance_scale=1,ddim_step=config.ddim_step)\n",
    "                        time_end=time.time()\n",
    "                        print('time cost:', time_end - time_start)\n",
    "\n",
    "                        sampledImgs=(sampledImgs+1)/2\n",
    "                        gt_image=(gt_image+1)/2\n",
    "                        lowlight_image=(lowlight_image+1)/2\n",
    "                        res_Imgs=np.clip(sampledImgs.detach().cpu().numpy()[0].transpose(1, 2, 0),0,1)[:,:,::-1] \n",
    "                        gt_img=np.clip(gt_image.detach().cpu().numpy()[0].transpose(1, 2, 0),0,1)[:,:,::-1]\n",
    "                        low_img=np.clip(lowlight_image.detach().cpu().numpy()[0].transpose(1, 2, 0),0,1)[:,:,::-1]\n",
    "                        \n",
    "                        \n",
    "                        # # Compute METRICS\n",
    "                        # ## compute psnr\n",
    "                        # psnr = PSNR(res_Imgs, gt_img)\n",
    "                        # #ssim = SSIM(res_Imgs, gt_img, channel_axis=2,data_range=255)\n",
    "                        # res_gray = rgb2gray(res_Imgs)\n",
    "                        # gt_gray = rgb2gray(gt_img)\n",
    "\n",
    "                        # ssim_score = SSIM(res_gray, gt_gray, multichannel=True,data_range=1)\\\n",
    "                        \n",
    "                        # #UIQM e UCIQE\n",
    "                        # uiqm,uciqe = nmetrics(res_Imgs)\n",
    "                    \n",
    "                        res_Imgs = (res_Imgs * 255)\n",
    "                        gt_img = (gt_img * 255)\n",
    "                        low_img = (low_img * 255)\n",
    "                        \n",
    "                        # psnr_list.append(psnr)\n",
    "                        # ssim_list.append(ssim_score)\n",
    "                        #uiqm_list.append(uiqm)\n",
    "                        #uciqe_list.append(uciqe)\n",
    "                        \n",
    "\n",
    "                        #send wandb\n",
    "                        output = np.concatenate([low_img, gt_img, res_Imgs], axis=1) / 255\n",
    "                        image = wandb.Image(output, caption=\"Low image, High Image, Control Enhanced Image\")\n",
    "                        wout.append(image)\n",
    "\n",
    "                        # show result\n",
    "                        # output = np.concatenate([low_img, gt_img, res_Imgs, res_trick], axis=1) / 255\n",
    "                        # plt.axis('off')\n",
    "                        # plt.imshow(output)\n",
    "                        # plt.show()\n",
    "                        #save_path = save_dir + name\n",
    "                        #cv2.imwrite(save_path, output * 255)\n",
    "\n",
    "                        save_path =save_dir+ name+'.png'\n",
    "                        cv2.imwrite(save_path, res_Imgs)\n",
    "                \n",
    "                #Metrics\n",
    "  \n",
    "                # avg_psnr = sum(psnr_list) / len(psnr_list)\n",
    "                # avg_ssim = sum(ssim_list) / len(ssim_list)\n",
    "                # avg_uiqm = sum(uiqm_list) / len(uiqm_list)\n",
    "                # avg_uciqe = sum(uciqe_list) / len(uciqe_list)\n",
    "\n",
    "                # Wandb logs \n",
    "                wandb.log({\"Inferecia \"+config.dataset:{\n",
    "                    \"Test from epoch\": epoch,\n",
    "                    \"Image Ajuste \":wout\n",
    "                    }})\n",
    "\n",
    "                #print('psnr_orgin_avg:', avg_psnr)\n",
    "                #print('ssim_orgin_avg:', avg_ssim)\n",
    "                print(f\"Test From epoch {epoch} DONE\")\n",
    "\n",
    "                # f = open(save_txt_name, 'w+')\n",
    "                # f.write('\\npsnr_orgin :')\n",
    "                # f.write(str(psnr_list))\n",
    "                # f.write('\\nssim_orgin :')\n",
    "                # f.write(str(ssim_list))\n",
    "\n",
    "                # f.write('\\npsnr_orgin_avg:')\n",
    "                # f.write(str(avg_psnr))\n",
    "                # f.write('\\nssim_orgin_avg:')\n",
    "                # f.write(str(avg_ssim))\n",
    "                # f.close()\n",
    "\n",
    "                #return avg_psnr,avg_ssim\n",
    "\n",
    "def Inference(config: Dict):\n",
    "   ###load the data\n",
    "    datapath_test = load_image_paths(config.dataset_path,config.dataset, split=False)\n",
    "\n",
    "    # load model and evaluate\n",
    "    device = config.device_list[0]\n",
    "\n",
    "    dataload_test = load_data_test(datapath_test,datapath_test)\n",
    "    dataloader = DataLoader(dataload_test, batch_size=1, num_workers=4,\n",
    "                            drop_last=True, pin_memory=True)\n",
    "\n",
    "    model = UNet(T=config.T, ch=config.channel, ch_mult=config.channel_mult,\n",
    "                 attn=config.attn,\n",
    "                 num_res_blocks=config.num_res_blocks, dropout=0.)\n",
    "    ckpt_path=config.pretrained_path\n",
    "    \n",
    "    ckpt = torch.load(ckpt_path,map_location='cpu')\n",
    "    model.load_state_dict({k.replace('module.', ''): v for k, v in ckpt.items()})\n",
    "    print(\"model load weight done.\")\n",
    "    \n",
    "    save_dir=config.output_path+'/result/'\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    save_txt_name =save_dir + 'res.txt'\n",
    "    #f = open(save_txt_name, 'w+')\n",
    "    #f.close()\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    sampler = GaussianDiffusionSampler(\n",
    "        model, config.beta_1, config.beta_T, config.T).to(device)\n",
    "    #loss_fn_vgg=lpips.LPIPS(net='vgg')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        with tqdm( dataloader, dynamic_ncols=True) as tqdmDataLoader:\n",
    "                image_num = 0\n",
    "                for data_low, data_color,data_blur in tqdmDataLoader:\n",
    "                    lowlight_image = data_low.to(device)\n",
    "\n",
    "                    data_color = data_color.to(device)\n",
    "                    data_blur=data_blur.to(device)\n",
    "                    snr_map = getSnrMap(lowlight_image, data_blur)\n",
    "                    \n",
    "                    #mask = mask.numpy()\n",
    "                    # print('type:',type(mask))\n",
    "                    print('data low shape:',data_low.shape)\n",
    "                    \n",
    "                    #print('mask shape:',mask.shape)\n",
    "                    # mask=cv2.resize(mask,(data_low.shape[2],data_low.shape[3]))\n",
    "                    mask=cv2.GaussianBlur(mask, (25, 25), 0)\n",
    "                    mask=torch.from_numpy(mask).to(device)\n",
    "                    # mask = torch.unsqueeze(mask, 0).to(device)\n",
    "                    # mask = np.ones([400, 600,1]) * 0\n",
    "                    # mask=torch.unsqueeze(mask,0).to(device)\n",
    "                    # mask[:, :, 100:400, 100:400] = 1\n",
    "                    \n",
    "                    data_concate=torch.cat([data_color, snr_map,mask], dim=1)\n",
    "\n",
    "                    for i in range(-8, 8): \n",
    "                        brightness_level = torch.ones([1]) * i\n",
    "                        brightness_level = brightness_level.to(device)\n",
    "                        \n",
    "                        time_start = time.time()\n",
    "                        sampledImgs = sampler(lowlight_image, data_concate,brightness_level,ddim=True,\n",
    "                                            unconditional_guidance_scale=1,ddim_step=config.ddim_step)\n",
    "                        time_end=time.time()\n",
    "                        print('time cost:', time_end - time_start)\n",
    "\n",
    "                        sampledImgs=(sampledImgs+1)/2\n",
    "                        res_Imgs=np.clip(sampledImgs.detach().cpu().numpy()[0].transpose(1, 2, 0),0,1)[:,:,::-1] \n",
    "\n",
    "                        wandb.log({\"Inference CLE_mask_DIF\":\n",
    "                                   {\"Mask Image Inference\": [wandb.Image(res_Imgs, caption=\"Image\")],\n",
    "                                   \"Mask Image Inference *255\": [wandb.Image(res_Imgs*255, caption=\"Image\")]}})\n",
    "                        save_path =save_dir+ config.data_name+'_level'+str(i)+'.png'\n",
    "                        print(save_path)\n",
    "                        cv2.imwrite(save_path, res_Imgs*255)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if __name__== \"__main__\" :\n",
    "    parser = argparse.ArgumentParser()\n",
    "    modelConfig = {\n",
    "  \n",
    "        \"DDP\": False,\n",
    "        \"state\": \"val\", # or eval\n",
    "        \"epoch\": 601,#10001,\n",
    "        \"batch_size\":16 ,\n",
    "        \"T\": 1000,\n",
    "        \"channel\": 128,\n",
    "        \"channel_mult\": [1, 2, 3, 4],\n",
    "        \"attn\": [2],\n",
    "        \"num_res_blocks\": 2,\n",
    "        \"dropout\": 0.15,\n",
    "        \"lr\": 5e-5,\n",
    "        \"multiplier\": 2.,\n",
    "        \"beta_1\": 1e-4,\n",
    "        \"beta_T\": 0.02,\n",
    "        \"img_size\": 32,\n",
    "        \"grad_clip\": 1.,\n",
    "        \"device\": \"cuda\", #MODIFIQUEI\n",
    "        \"device_list\": [0],\n",
    "        #\"device_list\": [3,2,1,0],\n",
    "        \n",
    "        \"ddim\":True,\n",
    "        \"unconditional_guidance_scale\":1,\n",
    "        \"ddim_step\":100\n",
    "    }\n",
    "\n",
    "\n",
    "    parser.add_argument('--dataset_path', type=str, default=\"./data/UDWdata/\")\n",
    "    parser.add_argument('--dataset', type=str, default=\"all\") # RUIE, UIEB, SUIM\n",
    "    parser.add_argument('--state', type=str, default=\"train\")  #or eval\n",
    "    parser.add_argument('--pretrained_path', type=str, default=None)  #or eval ajustar pastas para salvar os conteudos\n",
    "    parser.add_argument('--output_path', type=str, default=\"./output/\")  #or eval\n",
    "\n",
    "    config = parser.parse_args()\n",
    "    \n",
    "    wandb.init(\n",
    "            project=\"CLEDiffusion\",\n",
    "            config=vars(config),\n",
    "            name=\"Treino Diffusao sem mascaras\",\n",
    "            tags=[\"Train\",\"No mask\"],\n",
    "            group=\"diffusion_train\",\n",
    "            job_type=\"train\",\n",
    "\n",
    "        )\n",
    "    \n",
    "    for key, value in modelConfig.items():\n",
    "        setattr(config, key, value)\n",
    "    print(config)\n",
    "    Test(config,1000)\n",
    "\n",
    "    #Inference(config)\n",
    "    wandb.finish()\n",
    "    #Test_for_one(modelConfig,epoch=14000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[x] Ajustar codigo de teste\n",
    "[x] Ajustar codigo de Inferencia\n",
    "[x] Baixar pesos e colocar em uma pasta\n",
    "[] Testar codigo com os checkpoitns sem renomear\n",
    "qwwertyuiuoppasdfghjklç~zxcvbnm,."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CLEDiff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
