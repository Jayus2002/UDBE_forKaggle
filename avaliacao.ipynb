{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Controlable Light Enhencement for Underater Image Enhancement with difusion model\n",
    "Este notebook foi projetado para testar e avaliar este modelo e as técnicas utilizadas em sua construção. O método utilizado aqui é destinado à pesquisa na área de aprimoramento de imagens. A principal questão é saber se é possível que um modelo de difusão aprenda a melhorar uma imagem subaquática, particularmente suas características de brilho. O objetivo principal é fornecer uma imagem como entrada e um valor de brilho, e o modelo gerará uma nova imagem com iluminação aprimorada. Em outras palavras, o método visa alcançar o aprimoramento controlável da iluminação em toda a imagem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the necessary envoiriment for the validation\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dir data if not exists\n",
    "# download the dataset using gdown in this link\n",
    "# descompact \n",
    "# move the dataset for the root\n",
    "# make dir output if not exists\n",
    "# mke dir ckpt\n",
    "# make dir UIEB if not exists\n",
    "# download UIEB ckpt  using gdown in this link\n",
    "# descompact \n",
    "# move for the root\n",
    "# make dir RUIE if not exists\n",
    "# download RUIE ckpt using gdown in this link\n",
    "# descompact\n",
    "# move for the root\n",
    "# make dir SUIM if not exists\n",
    "# download SUIM ckpt using gdown in this link\n",
    "# descompact\n",
    "# move for the root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import gdown\n",
    "import zipfile\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs('data', exist_ok=True)\n",
    "os.makedirs('output', exist_ok=True)\n",
    "os.makedirs('ckpt', exist_ok=True)\n",
    "os.makedirs('UIEB', exist_ok=True)\n",
    "os.makedirs('RUIE', exist_ok=True)\n",
    "os.makedirs('SUIM', exist_ok=True)\n",
    "\n",
    "# Function to download, unzip and move files\n",
    "def download_and_unzip(url, extract_to, move_to):\n",
    "    # Download the file\n",
    "    output_file = os.path.join(extract_to, 'temp.zip')\n",
    "    gdown.download(url, output_file, quiet=False)\n",
    "    \n",
    "    # Unzip the file\n",
    "    with zipfile.ZipFile(output_file, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_to)\n",
    "    \n",
    "    # Move the contents to the specified directory\n",
    "    for item in os.listdir(extract_to):\n",
    "        item_path = os.path.join(extract_to, item)\n",
    "        os.rename(item_path, os.path.join(move_to, item))\n",
    "\n",
    "    # Remove the temporary zip file\n",
    "    os.remove(output_file)\n",
    "\n",
    "# Fill in the links for download\n",
    "dataset_link = 'INSERT_DATASET_LINK_HERE'\n",
    "uie_b_link = 'INSERT_UIEB_CKPT_LINK_HERE'\n",
    "ruie_link = 'INSERT_RUIE_CKPT_LINK_HERE'\n",
    "suim_link = 'INSERT_SUIM_CKPT_LINK_HERE'\n",
    "\n",
    "# Download, unzip and move the dataset\n",
    "download_and_unzip(dataset_link, 'data', '/content')\n",
    "\n",
    "# Download, unzip and move UIEB checkpoint\n",
    "download_and_unzip(uie_b_link, 'UIEB', '/content')\n",
    "\n",
    "# Download, unzip and move RUIE checkpoint\n",
    "download_and_unzip(ruie_link, 'RUIE', '/content')\n",
    "\n",
    "# Download, unzip and move SUIM checkpoint\n",
    "download_and_unzip(suim_link, 'SUIM', '/content')\n",
    "\n",
    "print(\"All files downloaded and organized successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load The datset data\n",
    "Give a look"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from src.train import load_data, load_data_test\n",
    "from src.split_data import load_image_paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def train_dataloader(dataloader, num_images=5):\n",
    "    # Itera sobre o DataLoader \n",
    "    for batch_idx, (data_low, data_high, data_color, data_blur) in enumerate(dataloader):\n",
    "        if batch_idx >= num_images:\n",
    "            break\n",
    "        # Plotagem das imagens\n",
    "        #Convertendo tensores para NumPy arrays para plotagem\n",
    "        image_low = np.transpose(data_low.detach().cpu().numpy(), (1, 2, 0))\n",
    "        image_high = np.transpose(data_high.detach().cpu().numpy(), (1, 2, 0))\n",
    "        image_color = np.transpose(data_color.detach().cpu().numpy(), (1, 2, 0))\n",
    "        image_blur = np.transpose(data_blur.detach().cpu().numpy(), (1, 2, 0))\n",
    "                # Transpose and print shapes\n",
    "        # print(f\"\"\"  data_low: {data_low.shape}\n",
    "        #                 data_high: {data_high.shape}\n",
    "        #                 data_color: {data_color.shape}\n",
    "        #                 data_blur: {data_blur.shape}\n",
    "        #                 image_low: {image_low.shape}\n",
    "        #                 image_high: {image_high.shape}\n",
    "        #                 image_color: {image_color.shape}\n",
    "        #                 image_blur: {image_blur.shape}\n",
    "        # \"\"\")\n",
    "        # Mostrando as imagens\n",
    "        plt.figure(figsize=(15, 5))\n",
    "\n",
    "        plt.subplot(1, 4, 1)\n",
    "        plt.imshow(image_low)\n",
    "        plt.title(\"Data Low\")\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1, 4, 2)\n",
    "        plt.imshow(image_high)\n",
    "        plt.title(\"Data High\")\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1, 4, 3)\n",
    "        plt.imshow(image_color)\n",
    "        plt.title(\"Data Color\")\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1, 4, 4)\n",
    "        plt.imshow(image_blur)\n",
    "        plt.title(\"Data Blur\")\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.show()\n",
    "def test_dataloader(dataloader, num_images=5):\n",
    "    # Itera sobre o DataLoader \n",
    "    for batch_idx, (data_low, data_high, data_color, data_blur, img) in enumerate(dataloader):\n",
    "        if batch_idx >= num_images:\n",
    "            break\n",
    "        # Plotagem das imagens\n",
    "        #Convertendo tensores para NumPy arrays para plotagem\n",
    "        image_low = np.transpose(data_low.detach().cpu().numpy(), (1, 2, 0))\n",
    "        image_high = np.transpose(data_high.detach().cpu().numpy(), (1, 2, 0))\n",
    "        image_color = np.transpose(data_color.detach().cpu().numpy(), (1, 2, 0))\n",
    "        image_blur = np.transpose(data_blur.detach().cpu().numpy(), (1, 2, 0))\n",
    "\n",
    "                # Transpose and print shapes\n",
    "        # print(f\"\"\"  data_low: {data_low.shape}\n",
    "        #                 data_high: {data_high.shape}\n",
    "        #                 data_color: {data_color.shape}\n",
    "        #                 data_blur: {data_blur.shape}\n",
    "        #                 image_low: {image_low.shape}\n",
    "        #                 image_high: {image_high.shape}\n",
    "        #                 image_color: {image_color.shape}\n",
    "        #                 image_blur: {image_blur.shape}\n",
    "        # \"\"\")\n",
    "        # Mostrando as imagens\n",
    "        plt.figure(figsize=(15, 5))\n",
    "\n",
    "        plt.subplot(1, 4, 1)\n",
    "        plt.imshow(image_low)\n",
    "        plt.title(\"Data test Low\")\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1, 4, 2)\n",
    "        plt.imshow(image_high)\n",
    "        plt.title(\"Data test High\")\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1, 4, 3)\n",
    "        plt.imshow(image_color)\n",
    "        plt.title(\"Data test Color\")\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1, 4, 4)\n",
    "        plt.imshow(image_blur)\n",
    "        plt.title(\"Data test Blur\")\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# Exemplo de uso:\n",
    "datapath_train,datapath_test = load_image_paths(dataset_path=\"data/UDWdata/\",dataset=\"UIEB\")\n",
    "train_loader=load_data(datapath_train, datapath_train)\n",
    "test_loader = load_data_test(datapath_test,datapath_test)\n",
    "# Suponha que você tenha um DataLoader chamado 'train_loader' com batch_size=4\n",
    "train_dataloader(train_loader, num_images=5)\n",
    "test_dataloader(test_loader, num_images=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acrescentar blur \n",
    "funcoes de perda\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
